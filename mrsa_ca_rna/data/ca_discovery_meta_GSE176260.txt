!Sample_title	"9B7F57 RNA-seq [discovery cohort]"	"880402 RNA-seq [discovery cohort]"	"8C9AD7 RNA-seq [discovery cohort]"	"E5B23A RNA-seq [discovery cohort]"	"B2E2B2 RNA-seq [discovery cohort]"	"1564C2 RNA-seq [discovery cohort]"	"0AD137 RNA-seq [discovery cohort]"	"26E5A9 RNA-seq [discovery cohort]"	"854EB9 RNA-seq [discovery cohort]"	"0ACB3C RNA-seq [discovery cohort]"	"B81885 RNA-seq [discovery cohort]"	"D81696 RNA-seq [discovery cohort]"	"EA1DEB RNA-seq [discovery cohort]"	"6539B0 RNA-seq [discovery cohort]"	"DEEEDD RNA-seq [discovery cohort]"	"457D38 RNA-seq [discovery cohort]"	"D1D1E6 RNA-seq [discovery cohort]"	"729D1F RNA-seq [discovery cohort]"	"9579EF RNA-seq [discovery cohort]"	"149572 RNA-seq [discovery cohort]"	"73BB9D RNA-seq [discovery cohort]"	"10557F RNA-seq [discovery cohort]"	"AB9F9C RNA-seq [discovery cohort]"	"B3FE2F RNA-seq [discovery cohort]"	"035D39 RNA-seq [discovery cohort]"	"B74D46 RNA-seq [discovery cohort]"	"7AC901 RNA-seq [discovery cohort]"	"8BE8F1 RNA-seq [discovery cohort]"	"A02C3C RNA-seq [discovery cohort]"	"15F8E6 RNA-seq [discovery cohort]"	"BFF127 RNA-seq [discovery cohort]"	"2954AF RNA-seq [discovery cohort]"	"E73C34 RNA-seq [discovery cohort]"	"D4DC91 RNA-seq [discovery cohort]"	"358631 RNA-seq [discovery cohort]"	"12F564 RNA-seq [discovery cohort]"	"187FB5 RNA-seq [discovery cohort]"	"689926 RNA-seq [discovery cohort]"	"072AAF RNA-seq [discovery cohort]"	"7C5B4C RNA-seq [discovery cohort]"	"1F1129 RNA-seq [discovery cohort]"	"DA611D RNA-seq [discovery cohort]"	"1B5838 RNA-seq [discovery cohort]"	"9C39BA RNA-seq [discovery cohort]"	"1A9D85 RNA-seq [discovery cohort]"	"D4461F RNA-seq [discovery cohort]"	"F6F5CF RNA-seq [discovery cohort]"	"A551F6 RNA-seq [discovery cohort]"	"AC46EF RNA-seq [discovery cohort]"	"428D4B RNA-seq [discovery cohort]"	"FC2181 RNA-seq [discovery cohort]"	"03DB8C RNA-seq [discovery cohort]"	"60AA21 RNA-seq [discovery cohort]"	"A5F80C RNA-seq [discovery cohort]"	"492B74 RNA-seq [discovery cohort]"	"F340EA RNA-seq [discovery cohort]"	"9A4D98 RNA-seq [discovery cohort]"	"2542D6 RNA-seq [discovery cohort]"	"21A948 RNA-seq [discovery cohort]"	"A17A52 RNA-seq [discovery cohort]"	"8E5C4B RNA-seq [discovery cohort]"	"1A75F8 RNA-seq [discovery cohort]"	"238571 RNA-seq [discovery cohort]"	"CC2540 RNA-seq [discovery cohort]"	"16A822 RNA-seq [discovery cohort]"	"CE05E6 RNA-seq [discovery cohort]"	"A5B941 RNA-seq [discovery cohort]"	"25EB02 RNA-seq [discovery cohort]"	"F6F4CE RNA-seq [discovery cohort]"	"0B7B8E RNA-seq [discovery cohort]"	"E4699F RNA-seq [discovery cohort]"	"D57F67 RNA-seq [discovery cohort]"	"38E5CC RNA-seq [discovery cohort]"	"C065E3 RNA-seq [discovery cohort]"	"3EBC9A RNA-seq [discovery cohort]"	"CE7EC9 RNA-seq [discovery cohort]"	"F13A8B RNA-seq [discovery cohort]"	"CE671D RNA-seq [discovery cohort]"	"F09062 RNA-seq [discovery cohort]"	"550E1F RNA-seq [discovery cohort]"	"CEDF02 RNA-seq [discovery cohort]"	"2893BF RNA-seq [discovery cohort]"	"F11533 RNA-seq [discovery cohort]"	"30BE58 RNA-seq [discovery cohort]"	"EF8B64 RNA-seq [discovery cohort]"	"6A4950 RNA-seq [discovery cohort]"	"7B7467 RNA-seq [discovery cohort]"	"EF3F92 RNA-seq [discovery cohort]"	"5FA0D1 RNA-seq [discovery cohort]"	"6768E2 RNA-seq [discovery cohort]"	"1BEAD8 RNA-seq [discovery cohort]"	"1C96D1 RNA-seq [discovery cohort]"	"C00657 RNA-seq [discovery cohort]"	"B34980 RNA-seq [discovery cohort]"	"AA5D47 RNA-seq [discovery cohort]"	"B46354 RNA-seq [discovery cohort]"	"15ABA5 RNA-seq [discovery cohort]"	"1DF6B5 RNA-seq [discovery cohort]"	"ABCF10 RNA-seq [discovery cohort]"	"95FDD3 RNA-seq [discovery cohort]"	"3EF5E6 RNA-seq [discovery cohort]"	"657833 RNA-seq [discovery cohort]"	"76909A RNA-seq [discovery cohort]"	"A391F4 RNA-seq [discovery cohort]"	"988122 RNA-seq [discovery cohort]"	"C9CA89 RNA-seq [discovery cohort]"	"5ED040 RNA-seq [discovery cohort]"	"B9E25D RNA-seq [discovery cohort]"	"6FE185 RNA-seq [discovery cohort]"	"2CCF63 RNA-seq [discovery cohort]"	"89F308 RNA-seq [discovery cohort]"	"3EC027 RNA-seq [discovery cohort]"	"FF54DA RNA-seq [discovery cohort]"	"AF6F08 RNA-seq [discovery cohort]"	"B0BE4B RNA-seq [discovery cohort]"	"868A6C RNA-seq [discovery cohort]"	"BBB8C9 RNA-seq [discovery cohort]"	"DFD737 RNA-seq [discovery cohort]"	"8D1302 RNA-seq [discovery cohort]"	"15CB28 RNA-seq [discovery cohort]"	"A1607B RNA-seq [discovery cohort]"	"9078C4 RNA-seq [discovery cohort]"	"40A9A6 RNA-seq [discovery cohort]"	"068397 RNA-seq [discovery cohort]"	"88C133 RNA-seq [discovery cohort]"	"33C83E RNA-seq [discovery cohort]"	"6834BB RNA-seq [discovery cohort]"	"AAB0AC RNA-seq [discovery cohort]"	"8893D9 RNA-seq [discovery cohort]"	"A21B60 RNA-seq [discovery cohort]"	"3118F9 RNA-seq [discovery cohort]"	"D631CF RNA-seq [discovery cohort]"	"0E1853 RNA-seq [discovery cohort]"	"8B0272 RNA-seq [discovery cohort]"	"F0597D RNA-seq [discovery cohort]"	"B72A01 RNA-seq [discovery cohort]"	"42F1DF RNA-seq [discovery cohort]"	"841518 RNA-seq [discovery cohort]"	"BEED9A RNA-seq [discovery cohort]"	"6A9D7F RNA-seq [discovery cohort]"	"DB7904 RNA-seq [discovery cohort]"	"F38CA4 RNA-seq [discovery cohort]"	"1D7D1A RNA-seq [discovery cohort]"	"F84F60 RNA-seq [discovery cohort]"	"BCD691 RNA-seq [discovery cohort]"	"E26B83 RNA-seq [discovery cohort]"	"4B0593 RNA-seq [discovery cohort]"	"B79790 RNA-seq [discovery cohort]"	"A5EFE2 RNA-seq [discovery cohort]"	"E720B5 RNA-seq [discovery cohort]"	"DA8B06 RNA-seq [discovery cohort]"	"73FE76 RNA-seq [discovery cohort]"	"DB7B6A RNA-seq [discovery cohort]"	"74ABD8 RNA-seq [discovery cohort]"	"631B85 RNA-seq [discovery cohort]"	"4C909F RNA-seq [discovery cohort]"	"034D3E RNA-seq [discovery cohort]"	"CE47EA RNA-seq [discovery cohort]"	"BA450F RNA-seq [discovery cohort]"	"51B816 RNA-seq [discovery cohort]"	"67104A RNA-seq [discovery cohort]"	"E439D8 RNA-seq [discovery cohort]"	"3F10C8 RNA-seq [discovery cohort]"	"A556E9 RNA-seq [discovery cohort]"	"8C1172 RNA-seq [discovery cohort]"	"1DFE91 RNA-seq [discovery cohort]"	"C7ECD8 RNA-seq [discovery cohort]"	"E089A5 RNA-seq [discovery cohort]"	"E8E29D RNA-seq [discovery cohort]"	"3DDBA9 RNA-seq [discovery cohort]"	"659728 RNA-seq [discovery cohort]"	"7C10AB RNA-seq [discovery cohort]"	"1DA5D8 RNA-seq [discovery cohort]"	"DD565A RNA-seq [discovery cohort]"	"29D1E4 RNA-seq [discovery cohort]"	"64CCA8 RNA-seq [discovery cohort]"	"622682 RNA-seq [discovery cohort]"	"7342D8 RNA-seq [discovery cohort]"	"C3EEA1 RNA-seq [discovery cohort]"	"4C847A RNA-seq [discovery cohort]"	"0F0D9D RNA-seq [discovery cohort]"	"0D9FAA RNA-seq [discovery cohort]"	"C2641E RNA-seq [discovery cohort]"	"234F85 RNA-seq [discovery cohort]"	"9A41FF RNA-seq [discovery cohort]"	"00DCD4 RNA-seq [discovery cohort]"	"290F5B RNA-seq [discovery cohort]"	"240899 RNA-seq [discovery cohort]"	"A2B906 RNA-seq [discovery cohort]"	"4E0C76 RNA-seq [discovery cohort]"	"8D34B5 RNA-seq [discovery cohort]"	"129FCD RNA-seq [discovery cohort]"	"CE0A65 RNA-seq [discovery cohort]"	"9379A7 RNA-seq [discovery cohort]"	"E7DA12 RNA-seq [discovery cohort]"	"AF59FA RNA-seq [discovery cohort]"	"3145EB RNA-seq [discovery cohort]"	"AB4CB3 RNA-seq [discovery cohort]"	"ADA0F2 RNA-seq [discovery cohort]"	"51D19E RNA-seq [discovery cohort]"	"B14A1D RNA-seq [discovery cohort]"	"8EAB34 RNA-seq [discovery cohort]"	"3E6743 RNA-seq [discovery cohort]"	"30C381 RNA-seq [discovery cohort]"	"FD2ECE RNA-seq [discovery cohort]"	"2193E8 RNA-seq [discovery cohort]"	"E09EAD RNA-seq [discovery cohort]"	"A65F40 RNA-seq [discovery cohort]"	"2456E9 RNA-seq [discovery cohort]"	"5A096A RNA-seq [discovery cohort]"	"5FCC0B RNA-seq [discovery cohort]"	"6A2540 RNA-seq [discovery cohort]"	"9A9B6C RNA-seq [discovery cohort]"	"DC3713 RNA-seq [discovery cohort]"	"605425 RNA-seq [discovery cohort]"	"F61C98 RNA-seq [discovery cohort]"	"422278 RNA-seq [discovery cohort]"	"FDB604 RNA-seq [discovery cohort]"	"82B1F0 RNA-seq [discovery cohort]"	"7E9D8A RNA-seq [discovery cohort]"	"532F9D RNA-seq [discovery cohort]"	"E53D42 RNA-seq [discovery cohort]"	"25AFAB RNA-seq [discovery cohort]"
!Sample_geo_accession	"GSM5360763"	"GSM5360764"	"GSM5360765"	"GSM5360766"	"GSM5360767"	"GSM5360768"	"GSM5360769"	"GSM5360770"	"GSM5360771"	"GSM5360772"	"GSM5360773"	"GSM5360774"	"GSM5360775"	"GSM5360776"	"GSM5360777"	"GSM5360778"	"GSM5360779"	"GSM5360780"	"GSM5360781"	"GSM5360782"	"GSM5360783"	"GSM5360784"	"GSM5360785"	"GSM5360786"	"GSM5360787"	"GSM5360788"	"GSM5360789"	"GSM5360790"	"GSM5360791"	"GSM5360792"	"GSM5360793"	"GSM5360794"	"GSM5360795"	"GSM5360796"	"GSM5360797"	"GSM5360798"	"GSM5360799"	"GSM5360800"	"GSM5360801"	"GSM5360802"	"GSM5360803"	"GSM5360804"	"GSM5360805"	"GSM5360806"	"GSM5360807"	"GSM5360808"	"GSM5360809"	"GSM5360810"	"GSM5360811"	"GSM5360812"	"GSM5360813"	"GSM5360814"	"GSM5360815"	"GSM5360816"	"GSM5360817"	"GSM5360818"	"GSM5360819"	"GSM5360820"	"GSM5360821"	"GSM5360822"	"GSM5360823"	"GSM5360824"	"GSM5360825"	"GSM5360826"	"GSM5360827"	"GSM5360828"	"GSM5360829"	"GSM5360830"	"GSM5360831"	"GSM5360832"	"GSM5360833"	"GSM5360834"	"GSM5360835"	"GSM5360836"	"GSM5360837"	"GSM5360838"	"GSM5360839"	"GSM5360840"	"GSM5360841"	"GSM5360842"	"GSM5360843"	"GSM5360844"	"GSM5360845"	"GSM5360846"	"GSM5360847"	"GSM5360848"	"GSM5360849"	"GSM5360850"	"GSM5360851"	"GSM5360852"	"GSM5360853"	"GSM5360854"	"GSM5360855"	"GSM5360856"	"GSM5360857"	"GSM5360858"	"GSM5360859"	"GSM5360860"	"GSM5360861"	"GSM5360862"	"GSM5360863"	"GSM5360864"	"GSM5360865"	"GSM5360866"	"GSM5360867"	"GSM5360868"	"GSM5360869"	"GSM5360870"	"GSM5360871"	"GSM5360872"	"GSM5360873"	"GSM5360874"	"GSM5360875"	"GSM5360876"	"GSM5360877"	"GSM5360878"	"GSM5360879"	"GSM5360880"	"GSM5360881"	"GSM5360882"	"GSM5360883"	"GSM5360884"	"GSM5360885"	"GSM5360886"	"GSM5360887"	"GSM5360888"	"GSM5360889"	"GSM5360890"	"GSM5360891"	"GSM5360892"	"GSM5360893"	"GSM5360894"	"GSM5360895"	"GSM5360896"	"GSM5360897"	"GSM5360898"	"GSM5360899"	"GSM5360900"	"GSM5360901"	"GSM5360902"	"GSM5360903"	"GSM5360904"	"GSM5360905"	"GSM5360906"	"GSM5360907"	"GSM5360908"	"GSM5360909"	"GSM5360910"	"GSM5360911"	"GSM5360912"	"GSM5360913"	"GSM5360914"	"GSM5360915"	"GSM5360916"	"GSM5360917"	"GSM5360918"	"GSM5360919"	"GSM5360920"	"GSM5360921"	"GSM5360922"	"GSM5360923"	"GSM5360924"	"GSM5360925"	"GSM5360926"	"GSM5360927"	"GSM5360928"	"GSM5360929"	"GSM5360930"	"GSM5360931"	"GSM5360932"	"GSM5360933"	"GSM5360934"	"GSM5360935"	"GSM5360936"	"GSM5360937"	"GSM5360938"	"GSM5360939"	"GSM5360940"	"GSM5360941"	"GSM5360942"	"GSM5360943"	"GSM5360944"	"GSM5360945"	"GSM5360946"	"GSM5360947"	"GSM5360948"	"GSM5360949"	"GSM5360950"	"GSM5360951"	"GSM5360952"	"GSM5360953"	"GSM5360954"	"GSM5360955"	"GSM5360956"	"GSM5360957"	"GSM5360958"	"GSM5360959"	"GSM5360960"	"GSM5360961"	"GSM5360962"	"GSM5360963"	"GSM5360964"	"GSM5360965"	"GSM5360966"	"GSM5360967"	"GSM5360968"	"GSM5360969"	"GSM5360970"	"GSM5360971"	"GSM5360972"	"GSM5360973"	"GSM5360974"	"GSM5360975"	"GSM5360976"	"GSM5360977"	"GSM5360978"	"GSM5360979"	"GSM5360980"	"GSM5360981"	"GSM5360982"	"GSM5360983"	"GSM5360984"	"GSM5360985"
!Sample_status	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"	"Public on Jun 08 2021"
!Sample_submission_date	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"	"Jun 07 2021"
!Sample_last_update_date	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"	"Jun 08 2021"
!Sample_type	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"	"SRA"
!Sample_channel_count	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"	"1"
!Sample_source_name_ch1	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"	"mRNA extracted from whole blood"
!Sample_organism_ch1	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"	"Homo sapiens"
!Sample_characteristics_ch1	"subject_id: 84011D"	"subject_id: FC2006"	"subject_id: 347C1F"	"subject_id: 5CFBB6"	"subject_id: CF91D0"	"subject_id: EF4C9D"	"subject_id: EF4C9D"	"subject_id: 471E8F"	"subject_id: 4A567E"	"subject_id: 727EA4"	"subject_id: E8D791"	"subject_id: E82DDB"	"subject_id: 0357E6"	"subject_id: 42772D"	"subject_id: DB720C"	"subject_id: 82F438"	"subject_id: 973A33"	"subject_id: 3BE656"	"subject_id: 1D1225"	"subject_id: 198582"	"subject_id: BFD336"	"subject_id: 7ECD7D"	"subject_id: EF4C9D"	"subject_id: C2F719"	"subject_id: 29C0AF"	"subject_id: 1E7D2D"	"subject_id: 702E7B"	"subject_id: A9C7F1"	"subject_id: 8108C1"	"subject_id: C2F719"	"subject_id: 9D9BF1"	"subject_id: 7F627A"	"subject_id: 5B3A64"	"subject_id: BC85E3"	"subject_id: 230F48"	"subject_id: 90E831"	"subject_id: 38F338"	"subject_id: EF4C9D"	"subject_id: F9808A"	"subject_id: 610287"	"subject_id: 471E8F"	"subject_id: 80AA45"	"subject_id: 09FFCF"	"subject_id: 1606DB"	"subject_id: 04F456"	"subject_id: 3A1EC1"	"subject_id: 267FBA"	"subject_id: B0575E"	"subject_id: 230F48"	"subject_id: 84B747"	"subject_id: 017738"	"subject_id: 2F7080"	"subject_id: E11D6E"	"subject_id: BB82EF"	"subject_id: 6CC558"	"subject_id: EF4C9D"	"subject_id: 07D165"	"subject_id: 3A73B4"	"subject_id: BAB782"	"subject_id: B3469C"	"subject_id: BB82EF"	"subject_id: 973A33"	"subject_id: BA0CF5"	"subject_id: B969FA"	"subject_id: 70A775"	"subject_id: 267FBA"	"subject_id: 0366AC"	"subject_id: 471E8F"	"subject_id: 72C318"	"subject_id: B25EAF"	"subject_id: BB82EF"	"subject_id: 1B2E17"	"subject_id: 91BB5B"	"subject_id: 1C33AA"	"subject_id: 40F1F7"	"subject_id: 567E33"	"subject_id: FAA710"	"subject_id: 22A88A"	"subject_id: 282462"	"subject_id: C28F5C"	"subject_id: 9DA8E5"	"subject_id: 89B341"	"subject_id: 9CD112"	"subject_id: 562482"	"subject_id: 019B4A"	"subject_id: 43F0B6"	"subject_id: 40EFF6"	"subject_id: 5731BE"	"subject_id: 6C702F"	"subject_id: 875C6D"	"subject_id: 3D4C66"	"subject_id: C28F5C"	"subject_id: B33B70"	"subject_id: C2F719"	"subject_id: C28F5C"	"subject_id: A91ECF"	"subject_id: 759E6F"	"subject_id: 09F02A"	"subject_id: 9E4B42"	"subject_id: 470D95"	"subject_id: C28F5C"	"subject_id: 1E7D2D"	"subject_id: C28F5C"	"subject_id: C90D5E"	"subject_id: C2F719"	"subject_id: EF4C9D"	"subject_id: 4EBA30"	"subject_id: 001659"	"subject_id: 5ADC6E"	"subject_id: 230F48"	"subject_id: 471E8F"	"subject_id: 282462"	"subject_id: 7138E6"	"subject_id: 46DB3A"	"subject_id: D04175"	"subject_id: 7D3991"	"subject_id: D845C3"	"subject_id: D328DF"	"subject_id: 282462"	"subject_id: FF8A03"	"subject_id: EEF191"	"subject_id: 5381F4"	"subject_id: B93B10"	"subject_id: C2B19B"	"subject_id: 089599"	"subject_id: 875C6D"	"subject_id: 7B9B77"	"subject_id: 62EDA5"	"subject_id: C2F719"	"subject_id: 931B4B"	"subject_id: 677DA6"	"subject_id: D6D61B"	"subject_id: 973A33"	"subject_id: 916BAE"	"subject_id: 84011D"	"subject_id: C28F5C"	"subject_id: BB82EF"	"subject_id: 13BE58"	"subject_id: 0EDAC3"	"subject_id: CCC4CC"	"subject_id: 282462"	"subject_id: 9E7A5C"	"subject_id: 84B747"	"subject_id: 84011D"	"subject_id: CA2E7C"	"subject_id: 28601D"	"subject_id: 16655A"	"subject_id: BF03EF"	"subject_id: 32CFA2"	"subject_id: 2F697E"	"subject_id: 7000F8"	"subject_id: C28F5C"	"subject_id: 20ED8C"	"subject_id: 413435"	"subject_id: 5B236D"	"subject_id: 84B3D6"	"subject_id: B7673F"	"subject_id: 09F02A"	"subject_id: 885376"	"subject_id: 7E3F31"	"subject_id: 0127EE"	"subject_id: 8C60B4"	"subject_id: C28F5C"	"subject_id: 47B981"	"subject_id: 7ECD7D"	"subject_id: 2FD9C7"	"subject_id: A530E5"	"subject_id: 9C9947"	"subject_id: 3F13B3"	"subject_id: 639608"	"subject_id: D70DCC"	"subject_id: CE7C37"	"subject_id: 471E8F"	"subject_id: 230F48"	"subject_id: 45E421"	"subject_id: 2A362E"	"subject_id: EAA6B5"	"subject_id: 1E7D2D"	"subject_id: E810BF"	"subject_id: C28F5C"	"subject_id: EF4C9D"	"subject_id: 1E9BB7"	"subject_id: 0B373E"	"subject_id: E92D54"	"subject_id: 471E8F"	"subject_id: 4D4EE4"	"subject_id: 31509D"	"subject_id: 47ECF2"	"subject_id: C87415"	"subject_id: EB58A2"	"subject_id: C28F5C"	"subject_id: 0D7A43"	"subject_id: EF4C9D"	"subject_id: 7C509B"	"subject_id: C60179"	"subject_id: 09F02A"	"subject_id: 2359B0"	"subject_id: EF4C9D"	"subject_id: 11E4DE"	"subject_id: 0678FC"	"subject_id: 010318"	"subject_id: C2F719"	"subject_id: 800A0F"	"subject_id: 282462"	"subject_id: 42772D"	"subject_id: 85F106"	"subject_id: E8D791"	"subject_id: 195D1F"	"subject_id: 471E8F"	"subject_id: 613C43"	"subject_id: 230F48"	"subject_id: 32D8B1"	"subject_id: 345229"	"subject_id: 909382"	"subject_id: E651E2"	"subject_id: 875C6D"	"subject_id: 471E8F"	"subject_id: 568CDF"	"subject_id: 471E8F"	"subject_id: 80AA45"	"subject_id: 640C6A"	"subject_id: CA038C"	"subject_id: EF4C9D"
!Sample_characteristics_ch1	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"	"passed sample qc: Pass"
!Sample_characteristics_ch1	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: No"	"discovery_analysis_sample: No"	"discovery_analysis_sample: No"	"discovery_analysis_sample: No"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: No"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: No"	"discovery_analysis_sample: No"	"discovery_analysis_sample: No"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: No"	"discovery_analysis_sample: No"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: No"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: No"	"discovery_analysis_sample: No"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: No"	"discovery_analysis_sample: No"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: No"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: No"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: No"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: No"	"discovery_analysis_sample: No"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: No"	"discovery_analysis_sample: No"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: No"	"discovery_analysis_sample: No"	"discovery_analysis_sample: No"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: No"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: No"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: No"	"discovery_analysis_sample: No"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: No"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: No"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: No"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: No"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: No"	"discovery_analysis_sample: No"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: No"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: No"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: No"	"discovery_analysis_sample: No"	"discovery_analysis_sample: No"	"discovery_analysis_sample: No"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: No"	"discovery_analysis_sample: No"	"discovery_analysis_sample: No"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: No"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: No"	"discovery_analysis_sample: No"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: No"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: No"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: No"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: No"	"discovery_analysis_sample: No"	"discovery_analysis_sample: No"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: No"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: No"	"discovery_analysis_sample: No"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: No"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: No"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: No"	"discovery_analysis_sample: No"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: No"	"discovery_analysis_sample: No"	"discovery_analysis_sample: No"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: No"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: No"	"discovery_analysis_sample: No"	"discovery_analysis_sample: No"	"discovery_analysis_sample: No"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: No"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: No"	"discovery_analysis_sample: No"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: No"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: No"	"discovery_analysis_sample: No"	"discovery_analysis_sample: No"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: No"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: No"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: No"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: No"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: No"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: No"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: No"	"discovery_analysis_sample: No"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: No"	"discovery_analysis_sample: Yes"	"discovery_analysis_sample: No"
!Sample_characteristics_ch1	"daysreltofirsttimepoin: 0"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: 39"	"daysreltofirsttimepoin: 20"	"daysreltofirsttimepoin: 32"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: 0"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: 0"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: 2"	"daysreltofirsttimepoin: 32"	"daysreltofirsttimepoin: 9"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: 43"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: 0"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: 4"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: 0"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: 46"	"daysreltofirsttimepoin: 17"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: 0"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: 26"	"daysreltofirsttimepoin: 0"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: 20"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: 11"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: 0"	"daysreltofirsttimepoin: 18"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: 15"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: 66"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: 2"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: 55"	"daysreltofirsttimepoin: 2"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: 15"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: 13"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: 11"	"daysreltofirsttimepoin: 8"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: 7"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: 37"	"daysreltofirsttimepoin: 0"	"daysreltofirsttimepoin: 15"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: 24"	"daysreltofirsttimepoin: 3"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: 7"	"daysreltofirsttimepoin: 53"	"daysreltofirsttimepoin: 0"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: 28"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: 0"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: 4"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: 29"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: 12"	"daysreltofirsttimepoin: 22"	"daysreltofirsttimepoin: 6"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: 53"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: 6"	"daysreltofirsttimepoin: 75"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: 29"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: 2"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: 0"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: 0"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: 25"	"daysreltofirsttimepoin: 19"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: 57"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: 43"	"daysreltofirsttimepoin: 13"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: 18"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: 6"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: 47"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: 0"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: 25"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: 2"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: 26"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: 2"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: 34"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: 21"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: 6"	"daysreltofirsttimepoin: 12"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: 0"	"daysreltofirsttimepoin: 0"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: NA"	"daysreltofirsttimepoin: 18"
!Sample_characteristics_ch1	"phenotype: Candidemia"	"phenotype: Healthy"	"phenotype: Viral"	"phenotype: Bacterial"	"phenotype: Healthy"	"phenotype: Mixed Candida/bacterial"	"phenotype: Mixed Candida/bacterial"	"phenotype: Candidemia"	"phenotype: Missing"	"phenotype: Bacterial"	"phenotype: Candidemia"	"phenotype: Healthy"	"phenotype: Viral"	"phenotype: Missing"	"phenotype: SIRS"	"phenotype: SIRS"	"phenotype: Candidemia"	"phenotype: Bacterial"	"phenotype: Viral"	"phenotype: Candidemia"	"phenotype: SIRS"	"phenotype: Candidemia"	"phenotype: Mixed Candida/bacterial"	"phenotype: Candidemia"	"phenotype: Healthy"	"phenotype: Candidemia"	"phenotype: Missing"	"phenotype: Bacterial"	"phenotype: Viral"	"phenotype: Candidemia"	"phenotype: Candidemia"	"phenotype: Viral"	"phenotype: Bacterial"	"phenotype: Viral"	"phenotype: Mixed Candida/bacterial"	"phenotype: Viral"	"phenotype: Missing"	"phenotype: Mixed Candida/bacterial"	"phenotype: Viral"	"phenotype: Healthy"	"phenotype: Candidemia"	"phenotype: Candidemia"	"phenotype: Healthy"	"phenotype: Candidemia"	"phenotype: Healthy"	"phenotype: Viral"	"phenotype: Candidemia"	"phenotype: Healthy"	"phenotype: Mixed Candida/bacterial"	"phenotype: Candidemia"	"phenotype: Viral"	"phenotype: SIRS"	"phenotype: Viral"	"phenotype: Mixed Candida/bacterial"	"phenotype: Bacterial"	"phenotype: Mixed Candida/bacterial"	"phenotype: SIRS"	"phenotype: Missing"	"phenotype: Missing"	"phenotype: Candidemia"	"phenotype: Mixed Candida/bacterial"	"phenotype: Candidemia"	"phenotype: Bacterial"	"phenotype: Viral"	"phenotype: Viral"	"phenotype: Candidemia"	"phenotype: Missing"	"phenotype: Candidemia"	"phenotype: Viral"	"phenotype: Bacterial"	"phenotype: Mixed Candida/bacterial"	"phenotype: Viral"	"phenotype: Bacterial"	"phenotype: Healthy"	"phenotype: Missing"	"phenotype: Viral"	"phenotype: SIRS"	"phenotype: SIRS"	"phenotype: Mixed Candida/bacterial"	"phenotype: Candidemia"	"phenotype: Viral"	"phenotype: Viral"	"phenotype: Candidemia"	"phenotype: Viral"	"phenotype: Missing"	"phenotype: Viral"	"phenotype: Missing"	"phenotype: Viral"	"phenotype: Bacterial"	"phenotype: Mixed Candida/bacterial"	"phenotype: Bacterial"	"phenotype: Candidemia"	"phenotype: Bacterial"	"phenotype: Candidemia"	"phenotype: Candidemia"	"phenotype: Viral"	"phenotype: Candidemia"	"phenotype: Candidemia"	"phenotype: SIRS"	"phenotype: Bacterial"	"phenotype: Candidemia"	"phenotype: Candidemia"	"phenotype: Candidemia"	"phenotype: Missing"	"phenotype: Candidemia"	"phenotype: Mixed Candida/bacterial"	"phenotype: Bacterial"	"phenotype: Bacterial"	"phenotype: Viral"	"phenotype: Mixed Candida/bacterial"	"phenotype: Candidemia"	"phenotype: Mixed Candida/bacterial"	"phenotype: Viral"	"phenotype: Viral"	"phenotype: Bacterial"	"phenotype: Candidemia"	"phenotype: Healthy"	"phenotype: Viral"	"phenotype: Mixed Candida/bacterial"	"phenotype: Viral"	"phenotype: Missing"	"phenotype: Missing"	"phenotype: Viral"	"phenotype: Bacterial"	"phenotype: Viral"	"phenotype: Mixed Candida/bacterial"	"phenotype: Viral"	"phenotype: Healthy"	"phenotype: Candidemia"	"phenotype: SIRS"	"phenotype: Bacterial"	"phenotype: Candidemia"	"phenotype: Candidemia"	"phenotype: Healthy"	"phenotype: Candidemia"	"phenotype: Candidemia"	"phenotype: Mixed Candida/bacterial"	"phenotype: Viral"	"phenotype: Viral"	"phenotype: Viral"	"phenotype: Mixed Candida/bacterial"	"phenotype: SIRS"	"phenotype: Candidemia"	"phenotype: Candidemia"	"phenotype: Bacterial"	"phenotype: Mixed Candida/bacterial"	"phenotype: Candidemia"	"phenotype: Bacterial"	"phenotype: Missing"	"phenotype: Bacterial"	"phenotype: Missing"	"phenotype: Candidemia"	"phenotype: Viral"	"phenotype: Bacterial"	"phenotype: SIRS"	"phenotype: Missing"	"phenotype: Missing"	"phenotype: Candidemia"	"phenotype: Bacterial"	"phenotype: SIRS"	"phenotype: SIRS"	"phenotype: Bacterial"	"phenotype: Candidemia"	"phenotype: Missing"	"phenotype: Candidemia"	"phenotype: Viral"	"phenotype: Healthy"	"phenotype: Viral"	"phenotype: Viral"	"phenotype: Viral"	"phenotype: Bacterial"	"phenotype: Candidemia"	"phenotype: Candidemia"	"phenotype: Mixed Candida/bacterial"	"phenotype: Missing"	"phenotype: Mixed Candida/bacterial"	"phenotype: Bacterial"	"phenotype: Candidemia"	"phenotype: Healthy"	"phenotype: Candidemia"	"phenotype: Mixed Candida/bacterial"	"phenotype: Viral"	"phenotype: Bacterial"	"phenotype: Viral"	"phenotype: Candidemia"	"phenotype: Viral"	"phenotype: Bacterial"	"phenotype: Viral"	"phenotype: Candidemia"	"phenotype: SIRS"	"phenotype: Candidemia"	"phenotype: Missing"	"phenotype: Mixed Candida/bacterial"	"phenotype: Bacterial"	"phenotype: Viral"	"phenotype: Candidemia"	"phenotype: Bacterial"	"phenotype: Mixed Candida/bacterial"	"phenotype: Bacterial"	"phenotype: Viral"	"phenotype: Healthy"	"phenotype: Candidemia"	"phenotype: Bacterial"	"phenotype: Mixed Candida/bacterial"	"phenotype: SIRS"	"phenotype: Viral"	"phenotype: Candidemia"	"phenotype: Viral"	"phenotype: Candidemia"	"phenotype: Bacterial"	"phenotype: Mixed Candida/bacterial"	"phenotype: SIRS"	"phenotype: Bacterial"	"phenotype: Viral"	"phenotype: Viral"	"phenotype: Mixed Candida/bacterial"	"phenotype: Candidemia"	"phenotype: Bacterial"	"phenotype: Candidemia"	"phenotype: Candidemia"	"phenotype: Missing"	"phenotype: SIRS"	"phenotype: Mixed Candida/bacterial"
!Sample_characteristics_ch1	"gender: Female"	"gender: Female"	"gender: Male"	"gender: Female"	"gender: Female"	"gender: Male"	"gender: Male"	"gender: Female"	"gender: Male"	"gender: Female"	"gender: Female"	"gender: Female"	"gender: Female"	"gender: NA"	"gender: Female"	"gender: Female"	"gender: Male"	"gender: Female"	"gender: Female"	"gender: Female"	"gender: Male"	"gender: Female"	"gender: Male"	"gender: Male"	"gender: Male"	"gender: Male"	"gender: Male"	"gender: Male"	"gender: Female"	"gender: Male"	"gender: Male"	"gender: Female"	"gender: Male"	"gender: Male"	"gender: Female"	"gender: Male"	"gender: Male"	"gender: Male"	"gender: Male"	"gender: Female"	"gender: Female"	"gender: Male"	"gender: Female"	"gender: Male"	"gender: Female"	"gender: Male"	"gender: Male"	"gender: Female"	"gender: Female"	"gender: Female"	"gender: Female"	"gender: Male"	"gender: Male"	"gender: Female"	"gender: Male"	"gender: Male"	"gender: Male"	"gender: Male"	"gender: NA"	"gender: Female"	"gender: Female"	"gender: Male"	"gender: Male"	"gender: Male"	"gender: Male"	"gender: Male"	"gender: Male"	"gender: Female"	"gender: Male"	"gender: Female"	"gender: Female"	"gender: Male"	"gender: Male"	"gender: Female"	"gender: Male"	"gender: Female"	"gender: Male"	"gender: Male"	"gender: Female"	"gender: Male"	"gender: Male"	"gender: Female"	"gender: Male"	"gender: Male"	"gender: Male"	"gender: Male"	"gender: Male"	"gender: Female"	"gender: Male"	"gender: Male"	"gender: Female"	"gender: Male"	"gender: Female"	"gender: Male"	"gender: Male"	"gender: Female"	"gender: Female"	"gender: Female"	"gender: Male"	"gender: Female"	"gender: Male"	"gender: Male"	"gender: Male"	"gender: Male"	"gender: Male"	"gender: Male"	"gender: Male"	"gender: Male"	"gender: Female"	"gender: Female"	"gender: Female"	"gender: Female"	"gender: Male"	"gender: Male"	"gender: Male"	"gender: Male"	"gender: Female"	"gender: Male"	"gender: Female"	"gender: Male"	"gender: Male"	"gender: Male"	"gender: Male"	"gender: Female"	"gender: Male"	"gender: Male"	"gender: Male"	"gender: Male"	"gender: Male"	"gender: Male"	"gender: Female"	"gender: Male"	"gender: Male"	"gender: Female"	"gender: Female"	"gender: Male"	"gender: Female"	"gender: Male"	"gender: Male"	"gender: Female"	"gender: Female"	"gender: Female"	"gender: Female"	"gender: Female"	"gender: Male"	"gender: Male"	"gender: Female"	"gender: Male"	"gender: Male"	"gender: Male"	"gender: Male"	"gender: Male"	"gender: Male"	"gender: Female"	"gender: Female"	"gender: Male"	"gender: Male"	"gender: Female"	"gender: Male"	"gender: Female"	"gender: Female"	"gender: Female"	"gender: Male"	"gender: Male"	"gender: Female"	"gender: Male"	"gender: Female"	"gender: Male"	"gender: Male"	"gender: Female"	"gender: Female"	"gender: Male"	"gender: Female"	"gender: Female"	"gender: Male"	"gender: Female"	"gender: Male"	"gender: Male"	"gender: Female"	"gender: Male"	"gender: Male"	"gender: Male"	"gender: Female"	"gender: Female"	"gender: Female"	"gender: Male"	"gender: Male"	"gender: Female"	"gender: Female"	"gender: Male"	"gender: Male"	"gender: Male"	"gender: Male"	"gender: Female"	"gender: Male"	"gender: Female"	"gender: Male"	"gender: Male"	"gender: Male"	"gender: Male"	"gender: Male"	"gender: Male"	"gender: Female"	"gender: Female"	"gender: Female"	"gender: Female"	"gender: Female"	"gender: Female"	"gender: Female"	"gender: Male"	"gender: Female"	"gender: Female"	"gender: Male"	"gender: Male"	"gender: Male"	"gender: Male"	"gender: Female"	"gender: Female"	"gender: Female"	"gender: Male"	"gender: Male"	"gender: Female"	"gender: Male"
!Sample_characteristics_ch1	"age: 50"	"age: 28"	"age: 72"	"age: 33"	"age: 20"	"age: 69"	"age: 69"	"age: 58"	"age: 66"	"age: 75"	"age: 45"	"age: 25"	"age: 18"	"age: NA"	"age: 58"	"age: 62"	"age: 27"	"age: 36"	"age: 73"	"age: 75"	"age: 54"	"age: 57"	"age: 69"	"age: 34"	"age: 20"	"age: 66"	"age: 69"	"age: 58"	"age: 46"	"age: 34"	"age: 69"	"age: 18"	"age: 51"	"age: 72"	"age: 20"	"age: 60"	"age: 68"	"age: 69"	"age: 66"	"age: 21"	"age: 58"	"age: 87"	"age: 18"	"age: 66"	"age: 20"	"age: 60"	"age: 75"	"age: 21"	"age: 20"	"age: 38"	"age: 18"	"age: 66"	"age: 48"	"age: 60"	"age: 72"	"age: 69"	"age: 35"	"age: 66"	"age: NA"	"age: 47"	"age: 60"	"age: 27"	"age: 61"	"age: 63"	"age: 83"	"age: 75"	"age: 64"	"age: 58"	"age: 13"	"age: 63"	"age: 60"	"age: 89"	"age: 51"	"age: 22"	"age: 64"	"age: 33"	"age: 58"	"age: 64"	"age: 44"	"age: 49"	"age: 60"	"age: 19"	"age: 62"	"age: 62"	"age: 66"	"age: 77"	"age: 69"	"age: 18"	"age: 81"	"age: 31"	"age: 52"	"age: 49"	"age: 69"	"age: 34"	"age: 49"	"age: 16"	"age: 36"	"age: 26"	"age: 58"	"age: 35"	"age: 49"	"age: 66"	"age: 49"	"age: 65"	"age: 34"	"age: 69"	"age: 76"	"age: 25"	"age: 18"	"age: 20"	"age: 58"	"age: 44"	"age: 18"	"age: 69"	"age: 52"	"age: 67"	"age: 21"	"age: 63"	"age: 44"	"age: 18"	"age: 63"	"age: 80"	"age: 70"	"age: 87"	"age: 68"	"age: 31"	"age: 59"	"age: 21"	"age: 34"	"age: 37"	"age: 51"	"age: NA"	"age: 27"	"age: 19"	"age: 50"	"age: 49"	"age: 60"	"age: 64"	"age: 68"	"age: 18"	"age: 44"	"age: 44"	"age: 38"	"age: 50"	"age: 70"	"age: 33"	"age: 33"	"age: 74"	"age: 67"	"age: 38"	"age: 63"	"age: 49"	"age: 27"	"age: 54"	"age: 73"	"age: 72"	"age: 74"	"age: 26"	"age: 69"	"age: 64"	"age: 47"	"age: 72"	"age: 49"	"age: 76"	"age: 57"	"age: 67"	"age: 21"	"age: 66"	"age: 71"	"age: 19"	"age: 85"	"age: 51"	"age: 58"	"age: 20"	"age: 86"	"age: 44"	"age: 65"	"age: 66"	"age: 18"	"age: 49"	"age: 69"	"age: 62"	"age: 81"	"age: 49"	"age: 58"	"age: 19"	"age: 54"	"age: 39"	"age: 73"	"age: 55"	"age: 49"	"age: 82"	"age: 69"	"age: 55"	"age: 16"	"age: 26"	"age: 80"	"age: 69"	"age: 60"	"age: 65"	"age: 18"	"age: 34"	"age: 49"	"age: 44"	"age: 88"	"age: 68"	"age: 45"	"age: 18"	"age: 58"	"age: 84"	"age: 20"	"age: 49"	"age: 79"	"age: 18"	"age: 67"	"age: 31"	"age: 58"	"age: 60"	"age: 58"	"age: 87"	"age: 71"	"age: 47"	"age: 69"
!Sample_characteristics_ch1	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: NA"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: NA"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 1"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"	"race_amind_alaskan: 0"
!Sample_characteristics_ch1	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: NA"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 1"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 1"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 1"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: NA"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"	"race_asian: 0"
!Sample_characteristics_ch1	"race_white: 1"	"race_white: 0"	"race_white: 0"	"race_white: 0"	"race_white: 1"	"race_white: 1"	"race_white: 1"	"race_white: 0"	"race_white: 0"	"race_white: 0"	"race_white: 1"	"race_white: 1"	"race_white: 0"	"race_white: NA"	"race_white: 0"	"race_white: 1"	"race_white: 1"	"race_white: 0"	"race_white: 0"	"race_white: 1"	"race_white: 0"	"race_white: 1"	"race_white: 1"	"race_white: 1"	"race_white: 0"	"race_white: 1"	"race_white: 0"	"race_white: 0"	"race_white: 1"	"race_white: 1"	"race_white: 0"	"race_white: 0"	"race_white: 0"	"race_white: 0"	"race_white: 0"	"race_white: 0"	"race_white: 0"	"race_white: 1"	"race_white: 0"	"race_white: 0"	"race_white: 0"	"race_white: 1"	"race_white: 1"	"race_white: 1"	"race_white: 0"	"race_white: 0"	"race_white: 1"	"race_white: 1"	"race_white: 0"	"race_white: 0"	"race_white: 0"	"race_white: 0"	"race_white: 0"	"race_white: 0"	"race_white: 1"	"race_white: 1"	"race_white: 1"	"race_white: 0"	"race_white: NA"	"race_white: 0"	"race_white: 0"	"race_white: 1"	"race_white: 1"	"race_white: 0"	"race_white: 0"	"race_white: 1"	"race_white: 0"	"race_white: 0"	"race_white: 1"	"race_white: 1"	"race_white: 0"	"race_white: 0"	"race_white: 1"	"race_white: 1"	"race_white: 0"	"race_white: 0"	"race_white: 0"	"race_white: 0"	"race_white: 0"	"race_white: 0"	"race_white: 0"	"race_white: 0"	"race_white: 1"	"race_white: 0"	"race_white: 0"	"race_white: 0"	"race_white: 0"	"race_white: 0"	"race_white: 0"	"race_white: 1"	"race_white: 0"	"race_white: 0"	"race_white: 0"	"race_white: 1"	"race_white: 0"	"race_white: 0"	"race_white: 0"	"race_white: 0"	"race_white: 0"	"race_white: 0"	"race_white: 0"	"race_white: 1"	"race_white: 0"	"race_white: 0"	"race_white: 1"	"race_white: 1"	"race_white: 0"	"race_white: 1"	"race_white: 0"	"race_white: 0"	"race_white: 0"	"race_white: 0"	"race_white: 0"	"race_white: 0"	"race_white: 0"	"race_white: 1"	"race_white: 1"	"race_white: 0"	"race_white: 0"	"race_white: 0"	"race_white: 0"	"race_white: 0"	"race_white: 0"	"race_white: 0"	"race_white: 0"	"race_white: 1"	"race_white: 0"	"race_white: 1"	"race_white: 1"	"race_white: 0"	"race_white: 0"	"race_white: 0"	"race_white: 1"	"race_white: 1"	"race_white: 1"	"race_white: 0"	"race_white: 0"	"race_white: 0"	"race_white: 0"	"race_white: 0"	"race_white: 0"	"race_white: 1"	"race_white: 0"	"race_white: 1"	"race_white: 0"	"race_white: 0"	"race_white: 0"	"race_white: 1"	"race_white: 0"	"race_white: 0"	"race_white: 0"	"race_white: 0"	"race_white: 0"	"race_white: 1"	"race_white: 0"	"race_white: 0"	"race_white: 0"	"race_white: 0"	"race_white: 0"	"race_white: 1"	"race_white: 0"	"race_white: 0"	"race_white: 0"	"race_white: 0"	"race_white: 1"	"race_white: 0"	"race_white: 1"	"race_white: 0"	"race_white: 0"	"race_white: 0"	"race_white: 0"	"race_white: 1"	"race_white: 0"	"race_white: 0"	"race_white: 0"	"race_white: 0"	"race_white: 1"	"race_white: 1"	"race_white: 0"	"race_white: 0"	"race_white: 1"	"race_white: 0"	"race_white: 1"	"race_white: 0"	"race_white: 0"	"race_white: 1"	"race_white: 0"	"race_white: 0"	"race_white: 1"	"race_white: 1"	"race_white: 0"	"race_white: 0"	"race_white: 1"	"race_white: 1"	"race_white: 1"	"race_white: 0"	"race_white: 0"	"race_white: 1"	"race_white: 0"	"race_white: 0"	"race_white: 0"	"race_white: 1"	"race_white: 0"	"race_white: 0"	"race_white: 0"	"race_white: 1"	"race_white: 1"	"race_white: 0"	"race_white: 0"	"race_white: 0"	"race_white: 0"	"race_white: 0"	"race_white: 0"	"race_white: 0"	"race_white: 0"	"race_white: 1"	"race_white: 0"	"race_white: 0"	"race_white: 0"	"race_white: 1"	"race_white: 0"	"race_white: 0"	"race_white: 1"
!Sample_characteristics_ch1	"race_black: 0"	"race_black: 0"	"race_black: 0"	"race_black: 0"	"race_black: 1"	"race_black: 0"	"race_black: 0"	"race_black: 1"	"race_black: 0"	"race_black: 0"	"race_black: 0"	"race_black: 0"	"race_black: 0"	"race_black: NA"	"race_black: 0"	"race_black: 0"	"race_black: 0"	"race_black: 0"	"race_black: 0"	"race_black: 0"	"race_black: 1"	"race_black: 0"	"race_black: 0"	"race_black: 0"	"race_black: 0"	"race_black: 0"	"race_black: 0"	"race_black: 1"	"race_black: 0"	"race_black: 0"	"race_black: 1"	"race_black: 0"	"race_black: 0"	"race_black: 0"	"race_black: 1"	"race_black: 0"	"race_black: 0"	"race_black: 0"	"race_black: 0"	"race_black: 0"	"race_black: 1"	"race_black: 0"	"race_black: 0"	"race_black: 0"	"race_black: 0"	"race_black: 0"	"race_black: 0"	"race_black: 0"	"race_black: 1"	"race_black: 1"	"race_black: 0"	"race_black: 0"	"race_black: 0"	"race_black: 1"	"race_black: 0"	"race_black: 0"	"race_black: 0"	"race_black: 0"	"race_black: NA"	"race_black: 1"	"race_black: 1"	"race_black: 0"	"race_black: 0"	"race_black: 0"	"race_black: 0"	"race_black: 0"	"race_black: 0"	"race_black: 1"	"race_black: 0"	"race_black: 0"	"race_black: 1"	"race_black: 0"	"race_black: 0"	"race_black: 0"	"race_black: 0"	"race_black: 1"	"race_black: 0"	"race_black: 0"	"race_black: 0"	"race_black: 1"	"race_black: 0"	"race_black: 0"	"race_black: 0"	"race_black: 0"	"race_black: 0"	"race_black: 0"	"race_black: 0"	"race_black: 0"	"race_black: 0"	"race_black: 0"	"race_black: 0"	"race_black: 1"	"race_black: 1"	"race_black: 0"	"race_black: 1"	"race_black: 0"	"race_black: 0"	"race_black: 1"	"race_black: 0"	"race_black: 0"	"race_black: 1"	"race_black: 0"	"race_black: 1"	"race_black: 0"	"race_black: 0"	"race_black: 0"	"race_black: 0"	"race_black: 0"	"race_black: 0"	"race_black: 1"	"race_black: 1"	"race_black: 0"	"race_black: 0"	"race_black: 0"	"race_black: 0"	"race_black: 0"	"race_black: 0"	"race_black: 0"	"race_black: 0"	"race_black: 0"	"race_black: 0"	"race_black: 0"	"race_black: 0"	"race_black: 0"	"race_black: 0"	"race_black: 0"	"race_black: 0"	"race_black: 0"	"race_black: 0"	"race_black: 1"	"race_black: 0"	"race_black: 0"	"race_black: 0"	"race_black: 0"	"race_black: 0"	"race_black: 1"	"race_black: 1"	"race_black: 0"	"race_black: 0"	"race_black: 0"	"race_black: 0"	"race_black: 0"	"race_black: 1"	"race_black: 0"	"race_black: 0"	"race_black: 1"	"race_black: 1"	"race_black: 0"	"race_black: 0"	"race_black: 0"	"race_black: 0"	"race_black: 1"	"race_black: 0"	"race_black: 0"	"race_black: 0"	"race_black: 0"	"race_black: 0"	"race_black: 1"	"race_black: 0"	"race_black: 0"	"race_black: 0"	"race_black: 0"	"race_black: 1"	"race_black: 0"	"race_black: 0"	"race_black: 0"	"race_black: 0"	"race_black: 0"	"race_black: 0"	"race_black: 0"	"race_black: 0"	"race_black: 0"	"race_black: 1"	"race_black: 1"	"race_black: 0"	"race_black: 0"	"race_black: 0"	"race_black: 0"	"race_black: 1"	"race_black: 1"	"race_black: 0"	"race_black: 0"	"race_black: 0"	"race_black: 1"	"race_black: 1"	"race_black: 0"	"race_black: 1"	"race_black: 1"	"race_black: 0"	"race_black: 0"	"race_black: 1"	"race_black: 0"	"race_black: 0"	"race_black: 0"	"race_black: 0"	"race_black: 1"	"race_black: 0"	"race_black: 0"	"race_black: 0"	"race_black: 0"	"race_black: 0"	"race_black: 0"	"race_black: 0"	"race_black: 0"	"race_black: 0"	"race_black: 0"	"race_black: 0"	"race_black: 0"	"race_black: 1"	"race_black: 0"	"race_black: 1"	"race_black: 0"	"race_black: 0"	"race_black: 0"	"race_black: 0"	"race_black: 0"	"race_black: 1"	"race_black: 0"	"race_black: 1"	"race_black: 0"	"race_black: 0"	"race_black: 0"	"race_black: 0"
!Sample_characteristics_ch1	"race_unknown: 0"	"race_unknown: 1"	"race_unknown: 1"	"race_unknown: 1"	"race_unknown: 0"	"race_unknown: 0"	"race_unknown: 0"	"race_unknown: 0"	"race_unknown: 1"	"race_unknown: 1"	"race_unknown: 0"	"race_unknown: 0"	"race_unknown: 1"	"race_unknown: NA"	"race_unknown: 1"	"race_unknown: 0"	"race_unknown: 0"	"race_unknown: 1"	"race_unknown: 0"	"race_unknown: 0"	"race_unknown: 0"	"race_unknown: 0"	"race_unknown: 0"	"race_unknown: 0"	"race_unknown: 0"	"race_unknown: 0"	"race_unknown: 1"	"race_unknown: 0"	"race_unknown: 0"	"race_unknown: 0"	"race_unknown: 0"	"race_unknown: 1"	"race_unknown: 1"	"race_unknown: 1"	"race_unknown: 0"	"race_unknown: 1"	"race_unknown: 1"	"race_unknown: 0"	"race_unknown: 1"	"race_unknown: 0"	"race_unknown: 0"	"race_unknown: 0"	"race_unknown: 0"	"race_unknown: 0"	"race_unknown: 0"	"race_unknown: 1"	"race_unknown: 0"	"race_unknown: 0"	"race_unknown: 0"	"race_unknown: 0"	"race_unknown: 1"	"race_unknown: 1"	"race_unknown: 0"	"race_unknown: 0"	"race_unknown: 0"	"race_unknown: 0"	"race_unknown: 0"	"race_unknown: 1"	"race_unknown: NA"	"race_unknown: 0"	"race_unknown: 0"	"race_unknown: 0"	"race_unknown: 0"	"race_unknown: 1"	"race_unknown: 1"	"race_unknown: 0"	"race_unknown: 1"	"race_unknown: 0"	"race_unknown: 0"	"race_unknown: 0"	"race_unknown: 0"	"race_unknown: 1"	"race_unknown: 0"	"race_unknown: 0"	"race_unknown: 1"	"race_unknown: 0"	"race_unknown: 1"	"race_unknown: 1"	"race_unknown: 0"	"race_unknown: 0"	"race_unknown: 1"	"race_unknown: 1"	"race_unknown: 0"	"race_unknown: 1"	"race_unknown: 1"	"race_unknown: 1"	"race_unknown: 1"	"race_unknown: 1"	"race_unknown: 1"	"race_unknown: 0"	"race_unknown: 1"	"race_unknown: 0"	"race_unknown: 0"	"race_unknown: 0"	"race_unknown: 0"	"race_unknown: 1"	"race_unknown: 0"	"race_unknown: 0"	"race_unknown: 1"	"race_unknown: 1"	"race_unknown: 0"	"race_unknown: 0"	"race_unknown: 0"	"race_unknown: 1"	"race_unknown: 0"	"race_unknown: 0"	"race_unknown: 1"	"race_unknown: 0"	"race_unknown: 1"	"race_unknown: 0"	"race_unknown: 0"	"race_unknown: 0"	"race_unknown: 1"	"race_unknown: 1"	"race_unknown: 1"	"race_unknown: 0"	"race_unknown: 0"	"race_unknown: 1"	"race_unknown: 0"	"race_unknown: 1"	"race_unknown: 1"	"race_unknown: 1"	"race_unknown: 1"	"race_unknown: 1"	"race_unknown: 1"	"race_unknown: 0"	"race_unknown: 1"	"race_unknown: 0"	"race_unknown: 0"	"race_unknown: 0"	"race_unknown: 1"	"race_unknown: 0"	"race_unknown: 0"	"race_unknown: 0"	"race_unknown: 0"	"race_unknown: 0"	"race_unknown: 0"	"race_unknown: 1"	"race_unknown: 1"	"race_unknown: 1"	"race_unknown: 0"	"race_unknown: 0"	"race_unknown: 0"	"race_unknown: 0"	"race_unknown: 0"	"race_unknown: 0"	"race_unknown: 0"	"race_unknown: 0"	"race_unknown: 1"	"race_unknown: 1"	"race_unknown: 1"	"race_unknown: 0"	"race_unknown: 1"	"race_unknown: 0"	"race_unknown: 1"	"race_unknown: 1"	"race_unknown: 1"	"race_unknown: 0"	"race_unknown: 1"	"race_unknown: 0"	"race_unknown: 1"	"race_unknown: 1"	"race_unknown: 0"	"race_unknown: 1"	"race_unknown: 0"	"race_unknown: 1"	"race_unknown: 0"	"race_unknown: 1"	"race_unknown: 1"	"race_unknown: 1"	"race_unknown: 1"	"race_unknown: 0"	"race_unknown: 0"	"race_unknown: 0"	"race_unknown: 1"	"race_unknown: 0"	"race_unknown: 0"	"race_unknown: 0"	"race_unknown: 0"	"race_unknown: 0"	"race_unknown: 0"	"race_unknown: 1"	"race_unknown: 0"	"race_unknown: 0"	"race_unknown: 0"	"race_unknown: 0"	"race_unknown: 0"	"race_unknown: 0"	"race_unknown: 0"	"race_unknown: 0"	"race_unknown: 0"	"race_unknown: 1"	"race_unknown: 0"	"race_unknown: 0"	"race_unknown: 0"	"race_unknown: 0"	"race_unknown: 1"	"race_unknown: 0"	"race_unknown: 1"	"race_unknown: 1"	"race_unknown: 0"	"race_unknown: 0"	"race_unknown: 1"	"race_unknown: 0"	"race_unknown: 1"	"race_unknown: 0"	"race_unknown: 0"	"race_unknown: 1"	"race_unknown: 0"	"race_unknown: 1"	"race_unknown: 0"	"race_unknown: 1"	"race_unknown: 1"	"race_unknown: 1"	"race_unknown: 1"	"race_unknown: 0"	"race_unknown: 0"	"race_unknown: 1"	"race_unknown: 0"	"race_unknown: 0"	"race_unknown: 1"	"race_unknown: 1"	"race_unknown: 0"
!Sample_characteristics_ch1	"race_other: 0"	"race_other: 1"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 1"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 1"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: NA"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 1"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 1"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 1"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 1"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 1"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 1"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 1"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 1"	"race_other: 0"	"race_other: 0"	"race_other: 1"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"	"race_other: 0"
!Sample_molecule_ch1	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"	"polyA RNA"
!Sample_extract_protocol_ch1	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"	"Total RNA was extracted from human blood preserved and stored in PAXgene Blood RNA Tubes using the Qiagen PAXgene Blood miRNA Kit according to the manufacturers protoco"
!Sample_extract_protocol_ch1	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"	"RNA sequencing libraries were generated using NuGEN Universal mRNA-seq kit with AnyDeplete Globin (NuGEN Technologies, Redwood City, CA) and sequenced on the Illumina NovaSeq 6000 instrument with S2 flow cell and 50bp paired-end reads (performed through the Duke Sequencing and Genomic Technologies Core)"
!Sample_taxid_ch1	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"	"9606"
!Sample_description	"408954_S60"	"CRO32-2_S30"	"408901_S15"	"95971_S21"	"CRO40-2_S68"	"RNA347-138_S60"	"RNA347-97_S57"	"RNA355-70_S45"	"408929_S40"	"97392_S28"	"408933_S44"	"CRO38-2_S70"	"105812_S39"	"286643_S63"	"286636_S61"	"286605_S57"	"408957_S62"	"96002_S25"	"14-005_S12"	"136884_S71"	"14-015_S16"	"408969_S72"	"RNA347-130_S59"	"408936_S47"	"CRO34-2_S74"	"408943_S51"	"408925_S36"	"14-006_S13"	"105889_S51"	"408971_S73"	"RNA329-1_S31"	"105796_S38"	"97396_S32"	"408907_S20"	"408951_S57"	"408930_S41"	"408927_S38"	"RNA347-1_S52"	"408919_S31"	"CRO39-2_S69"	"RNA355-92_S47"	"RNA340-19_S22"	"CRO33-2_S32"	"408937_S48"	"CRO41-2_S67"	"408914_S26"	"408953_S59"	"CRO44-2_S64"	"RNA353-85_S41"	"RNA316-1_S26"	"105826_S45"	"09-037_S8"	"14-011_S15"	"RNA350-59_S51"	"408977_S4"	"RNA347-36_S54"	"09-006_S2"	"408904_S17"	"408932_S43"	"136888_S74"	"408947_S54"	"408958_S63"	"408984_S69"	"408928_S39"	"408912_S24"	"408946_S53"	"408895_S9"	"RNA355-106_S49"	"136873_S1"	"408982_S8"	"408948_S55"	"408893_S7"	"408979_S6"	"CRO37-2_S71"	"408899_S13"	"09-011_S4"	"286638_S62"	"286631_S60"	"408960_S65"	"A6-21_S11"	"408905_S18"	"105822_S43"	"408944_S52"	"408896_S10"	"408909_S21"	"408922_S34"	"408913_S25"	"105821_S42"	"97407_S35"	"408964_S68"	"95997_S24"	"A6-82_S14"	"408974_S2"	"408961_S66"	"A6-62_S13"	"105853_S48"	"136889_S75"	"RNA352-35_S38"	"286691_S67"	"95991_S22"	"A6-147_S18"	"408942_S50"	"A6-104_S15"	"408917_S29"	"408962_S67"	"RNA347-16_S53"	"95968_S19"	"09-019_S6"	"105794_S37"	"RNA353-36_S39"	"RNA355-99_S48"	"408967_S70"	"105819_S41"	"408906_S19"	"97390_S27"	"RNA320-1_S28"	"CRO35-2_S73"	"408915_S27"	"RNA341-29_S24"	"105841_S46"	"408921_S33"	"408888_S2"	"408891_S5"	"97394_S30"	"408916_S28"	"408935_S46"	"105861_S50"	"CRO43-2_S65"	"408973_S1"	"286600_S56"	"95994_S36"	"136887_S73"	"408959_S64"	"CRO42-2_S66"	"408956_S61"	"A6-131_S16"	"408949_S56"	"408898_S12"	"408918_S30"	"105926_S54"	"RNA341-37_S25"	"09-014_S5"	"RNA316-18_S27"	"RNA348-59_S50"	"408985_S70"	"A7-1_S20"	"136885_S72"	"408983_S9"	"408890_S4"	"97393_S29"	"408923_S35"	"A6-139_S17"	"105856_S49"	"10-026_S11"	"286686_S66"	"408910_S22"	"408931_S42"	"RNA352-21_S37"	"97389_S26"	"14-010_S14"	"286685_S65"	"95966_S18"	"A6-5_S10"	"408894_S8"	"408968_S71"	"408900_S14"	"CRO46-2_S62"	"408911_S23"	"408903_S16"	"105813_S40"	"97406_S34"	"RNA331-2_S33"	"RNA355-55_S44"	"408952_S58"	"408892_S6"	"RNA332-1_S34"	"408981_S7"	"RNA351-29_S35"	"CRO36-2_S72"	"A6-155_S19"	"RNA347-55_S55"	"408920_S32"	"408975_S3"	"105911_S53"	"RNA355-35_S43"	"10-024_S10"	"09-035_S7"	"105907_S52"	"RNA323-1_S29"	"286606_S58"	"A6-42_S12"	"408887_S1"	"RNA347-151_S61"	"408978_S5"	"105848_S47"	"RNA352-1_S36"	"97403_S33"	"RNA347-112_S58"	"94183_S17"	"408897_S11"	"CRO45-2_S63"	"408972_S74"	"10-013_S9"	"RNA341-21_S23"	"286684_S64"	"09-008_S3"	"408934_S45"	"105824_S44"	"RNA355-78_S46"	"97395_S31"	"RNA353-70_S40"	"286695_S68"	"95970_S20"	"105927_S55"	"408889_S3"	"408966_S69"	"RNA355-18_S42"	"95996_S23"	"408940_S49"	"RNA340-1_S21"	"408926_S37"	"286627_S59"	"RNA347-76_S56"
!Sample_description	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"	"processed data file:"
!Sample_description	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"	"QCed_counts_exploratory.txt"
!Sample_description	"QCed_counts_discovery.txt"	"QCed_counts_discovery.txt"	"QCed_counts_discovery.txt"	"QCed_counts_discovery.txt"	"QCed_counts_discovery.txt"	""	""	""	""	"QCed_counts_discovery.txt"	"QCed_counts_discovery.txt"	"QCed_counts_discovery.txt"	"QCed_counts_discovery.txt"	""	"QCed_counts_discovery.txt"	"QCed_counts_discovery.txt"	"QCed_counts_discovery.txt"	"QCed_counts_discovery.txt"	"QCed_counts_discovery.txt"	"QCed_counts_discovery.txt"	"QCed_counts_discovery.txt"	""	""	""	"QCed_counts_discovery.txt"	""	""	"QCed_counts_discovery.txt"	"QCed_counts_discovery.txt"	"QCed_counts_discovery.txt"	"QCed_counts_discovery.txt"	"QCed_counts_discovery.txt"	"QCed_counts_discovery.txt"	"QCed_counts_discovery.txt"	""	"QCed_counts_discovery.txt"	""	""	"QCed_counts_discovery.txt"	"QCed_counts_discovery.txt"	""	""	"QCed_counts_discovery.txt"	"QCed_counts_discovery.txt"	"QCed_counts_discovery.txt"	"QCed_counts_discovery.txt"	"QCed_counts_discovery.txt"	"QCed_counts_discovery.txt"	""	"QCed_counts_discovery.txt"	"QCed_counts_discovery.txt"	"QCed_counts_discovery.txt"	"QCed_counts_discovery.txt"	""	"QCed_counts_discovery.txt"	""	"QCed_counts_discovery.txt"	""	""	"QCed_counts_discovery.txt"	""	""	"QCed_counts_discovery.txt"	"QCed_counts_discovery.txt"	"QCed_counts_discovery.txt"	""	""	""	"QCed_counts_discovery.txt"	"QCed_counts_discovery.txt"	""	"QCed_counts_discovery.txt"	"QCed_counts_discovery.txt"	"QCed_counts_discovery.txt"	""	"QCed_counts_discovery.txt"	"QCed_counts_discovery.txt"	"QCed_counts_discovery.txt"	""	""	"QCed_counts_discovery.txt"	"QCed_counts_discovery.txt"	"QCed_counts_discovery.txt"	"QCed_counts_discovery.txt"	""	"QCed_counts_discovery.txt"	""	"QCed_counts_discovery.txt"	"QCed_counts_discovery.txt"	""	"QCed_counts_discovery.txt"	""	"QCed_counts_discovery.txt"	""	""	"QCed_counts_discovery.txt"	"QCed_counts_discovery.txt"	""	"QCed_counts_discovery.txt"	"QCed_counts_discovery.txt"	""	"QCed_counts_discovery.txt"	""	""	""	""	"QCed_counts_discovery.txt"	"QCed_counts_discovery.txt"	"QCed_counts_discovery.txt"	""	""	""	"QCed_counts_discovery.txt"	"QCed_counts_discovery.txt"	"QCed_counts_discovery.txt"	"QCed_counts_discovery.txt"	"QCed_counts_discovery.txt"	"QCed_counts_discovery.txt"	""	"QCed_counts_discovery.txt"	""	""	"QCed_counts_discovery.txt"	"QCed_counts_discovery.txt"	"QCed_counts_discovery.txt"	""	"QCed_counts_discovery.txt"	"QCed_counts_discovery.txt"	""	"QCed_counts_discovery.txt"	"QCed_counts_discovery.txt"	"QCed_counts_discovery.txt"	""	"QCed_counts_discovery.txt"	""	""	""	"QCed_counts_discovery.txt"	"QCed_counts_discovery.txt"	"QCed_counts_discovery.txt"	""	"QCed_counts_discovery.txt"	""	""	"QCed_counts_discovery.txt"	""	"QCed_counts_discovery.txt"	"QCed_counts_discovery.txt"	""	"QCed_counts_discovery.txt"	""	""	"QCed_counts_discovery.txt"	"QCed_counts_discovery.txt"	"QCed_counts_discovery.txt"	""	""	""	"QCed_counts_discovery.txt"	"QCed_counts_discovery.txt"	"QCed_counts_discovery.txt"	"QCed_counts_discovery.txt"	"QCed_counts_discovery.txt"	""	"QCed_counts_discovery.txt"	"QCed_counts_discovery.txt"	"QCed_counts_discovery.txt"	"QCed_counts_discovery.txt"	"QCed_counts_discovery.txt"	"QCed_counts_discovery.txt"	"QCed_counts_discovery.txt"	"QCed_counts_discovery.txt"	""	""	""	""	"QCed_counts_discovery.txt"	""	"QCed_counts_discovery.txt"	""	""	"QCed_counts_discovery.txt"	"QCed_counts_discovery.txt"	"QCed_counts_discovery.txt"	""	"QCed_counts_discovery.txt"	"QCed_counts_discovery.txt"	"QCed_counts_discovery.txt"	"QCed_counts_discovery.txt"	"QCed_counts_discovery.txt"	""	""	""	"QCed_counts_discovery.txt"	"QCed_counts_discovery.txt"	"QCed_counts_discovery.txt"	"QCed_counts_discovery.txt"	""	"QCed_counts_discovery.txt"	"QCed_counts_discovery.txt"	"QCed_counts_discovery.txt"	""	"QCed_counts_discovery.txt"	""	"QCed_counts_discovery.txt"	"QCed_counts_discovery.txt"	""	"QCed_counts_discovery.txt"	""	"QCed_counts_discovery.txt"	""	"QCed_counts_discovery.txt"	"QCed_counts_discovery.txt"	"QCed_counts_discovery.txt"	"QCed_counts_discovery.txt"	""	""	"QCed_counts_discovery.txt"	"QCed_counts_discovery.txt"	"QCed_counts_discovery.txt"	""	"QCed_counts_discovery.txt"	""
!Sample_description	"Log2_normalized_expression_discovery.txt"	"Log2_normalized_expression_discovery.txt"	"Log2_normalized_expression_discovery.txt"	"Log2_normalized_expression_discovery.txt"	"Log2_normalized_expression_discovery.txt"	""	""	""	""	"Log2_normalized_expression_discovery.txt"	"Log2_normalized_expression_discovery.txt"	"Log2_normalized_expression_discovery.txt"	"Log2_normalized_expression_discovery.txt"	""	"Log2_normalized_expression_discovery.txt"	"Log2_normalized_expression_discovery.txt"	"Log2_normalized_expression_discovery.txt"	"Log2_normalized_expression_discovery.txt"	"Log2_normalized_expression_discovery.txt"	"Log2_normalized_expression_discovery.txt"	"Log2_normalized_expression_discovery.txt"	""	""	""	"Log2_normalized_expression_discovery.txt"	""	""	"Log2_normalized_expression_discovery.txt"	"Log2_normalized_expression_discovery.txt"	"Log2_normalized_expression_discovery.txt"	"Log2_normalized_expression_discovery.txt"	"Log2_normalized_expression_discovery.txt"	"Log2_normalized_expression_discovery.txt"	"Log2_normalized_expression_discovery.txt"	""	"Log2_normalized_expression_discovery.txt"	""	""	"Log2_normalized_expression_discovery.txt"	"Log2_normalized_expression_discovery.txt"	""	""	"Log2_normalized_expression_discovery.txt"	"Log2_normalized_expression_discovery.txt"	"Log2_normalized_expression_discovery.txt"	"Log2_normalized_expression_discovery.txt"	"Log2_normalized_expression_discovery.txt"	"Log2_normalized_expression_discovery.txt"	""	"Log2_normalized_expression_discovery.txt"	"Log2_normalized_expression_discovery.txt"	"Log2_normalized_expression_discovery.txt"	"Log2_normalized_expression_discovery.txt"	""	"Log2_normalized_expression_discovery.txt"	""	"Log2_normalized_expression_discovery.txt"	""	""	"Log2_normalized_expression_discovery.txt"	""	""	"Log2_normalized_expression_discovery.txt"	"Log2_normalized_expression_discovery.txt"	"Log2_normalized_expression_discovery.txt"	""	""	""	"Log2_normalized_expression_discovery.txt"	"Log2_normalized_expression_discovery.txt"	""	"Log2_normalized_expression_discovery.txt"	"Log2_normalized_expression_discovery.txt"	"Log2_normalized_expression_discovery.txt"	""	"Log2_normalized_expression_discovery.txt"	"Log2_normalized_expression_discovery.txt"	"Log2_normalized_expression_discovery.txt"	""	""	"Log2_normalized_expression_discovery.txt"	"Log2_normalized_expression_discovery.txt"	"Log2_normalized_expression_discovery.txt"	"Log2_normalized_expression_discovery.txt"	""	"Log2_normalized_expression_discovery.txt"	""	"Log2_normalized_expression_discovery.txt"	"Log2_normalized_expression_discovery.txt"	""	"Log2_normalized_expression_discovery.txt"	""	"Log2_normalized_expression_discovery.txt"	""	""	"Log2_normalized_expression_discovery.txt"	"Log2_normalized_expression_discovery.txt"	""	"Log2_normalized_expression_discovery.txt"	"Log2_normalized_expression_discovery.txt"	""	"Log2_normalized_expression_discovery.txt"	""	""	""	""	"Log2_normalized_expression_discovery.txt"	"Log2_normalized_expression_discovery.txt"	"Log2_normalized_expression_discovery.txt"	""	""	""	"Log2_normalized_expression_discovery.txt"	"Log2_normalized_expression_discovery.txt"	"Log2_normalized_expression_discovery.txt"	"Log2_normalized_expression_discovery.txt"	"Log2_normalized_expression_discovery.txt"	"Log2_normalized_expression_discovery.txt"	""	"Log2_normalized_expression_discovery.txt"	""	""	"Log2_normalized_expression_discovery.txt"	"Log2_normalized_expression_discovery.txt"	"Log2_normalized_expression_discovery.txt"	""	"Log2_normalized_expression_discovery.txt"	"Log2_normalized_expression_discovery.txt"	""	"Log2_normalized_expression_discovery.txt"	"Log2_normalized_expression_discovery.txt"	"Log2_normalized_expression_discovery.txt"	""	"Log2_normalized_expression_discovery.txt"	""	""	""	"Log2_normalized_expression_discovery.txt"	"Log2_normalized_expression_discovery.txt"	"Log2_normalized_expression_discovery.txt"	""	"Log2_normalized_expression_discovery.txt"	""	""	"Log2_normalized_expression_discovery.txt"	""	"Log2_normalized_expression_discovery.txt"	"Log2_normalized_expression_discovery.txt"	""	"Log2_normalized_expression_discovery.txt"	""	""	"Log2_normalized_expression_discovery.txt"	"Log2_normalized_expression_discovery.txt"	"Log2_normalized_expression_discovery.txt"	""	""	""	"Log2_normalized_expression_discovery.txt"	"Log2_normalized_expression_discovery.txt"	"Log2_normalized_expression_discovery.txt"	"Log2_normalized_expression_discovery.txt"	"Log2_normalized_expression_discovery.txt"	""	"Log2_normalized_expression_discovery.txt"	"Log2_normalized_expression_discovery.txt"	"Log2_normalized_expression_discovery.txt"	"Log2_normalized_expression_discovery.txt"	"Log2_normalized_expression_discovery.txt"	"Log2_normalized_expression_discovery.txt"	"Log2_normalized_expression_discovery.txt"	"Log2_normalized_expression_discovery.txt"	""	""	""	""	"Log2_normalized_expression_discovery.txt"	""	"Log2_normalized_expression_discovery.txt"	""	""	"Log2_normalized_expression_discovery.txt"	"Log2_normalized_expression_discovery.txt"	"Log2_normalized_expression_discovery.txt"	""	"Log2_normalized_expression_discovery.txt"	"Log2_normalized_expression_discovery.txt"	"Log2_normalized_expression_discovery.txt"	"Log2_normalized_expression_discovery.txt"	"Log2_normalized_expression_discovery.txt"	""	""	""	"Log2_normalized_expression_discovery.txt"	"Log2_normalized_expression_discovery.txt"	"Log2_normalized_expression_discovery.txt"	"Log2_normalized_expression_discovery.txt"	""	"Log2_normalized_expression_discovery.txt"	"Log2_normalized_expression_discovery.txt"	"Log2_normalized_expression_discovery.txt"	""	"Log2_normalized_expression_discovery.txt"	""	"Log2_normalized_expression_discovery.txt"	"Log2_normalized_expression_discovery.txt"	""	"Log2_normalized_expression_discovery.txt"	""	"Log2_normalized_expression_discovery.txt"	""	"Log2_normalized_expression_discovery.txt"	"Log2_normalized_expression_discovery.txt"	"Log2_normalized_expression_discovery.txt"	"Log2_normalized_expression_discovery.txt"	""	""	"Log2_normalized_expression_discovery.txt"	"Log2_normalized_expression_discovery.txt"	"Log2_normalized_expression_discovery.txt"	""	"Log2_normalized_expression_discovery.txt"	""
!Sample_description	"Voom_weights_discovery.txt"	"Voom_weights_discovery.txt"	"Voom_weights_discovery.txt"	"Voom_weights_discovery.txt"	"Voom_weights_discovery.txt"	""	""	""	""	"Voom_weights_discovery.txt"	"Voom_weights_discovery.txt"	"Voom_weights_discovery.txt"	"Voom_weights_discovery.txt"	""	"Voom_weights_discovery.txt"	"Voom_weights_discovery.txt"	"Voom_weights_discovery.txt"	"Voom_weights_discovery.txt"	"Voom_weights_discovery.txt"	"Voom_weights_discovery.txt"	"Voom_weights_discovery.txt"	""	""	""	"Voom_weights_discovery.txt"	""	""	"Voom_weights_discovery.txt"	"Voom_weights_discovery.txt"	"Voom_weights_discovery.txt"	"Voom_weights_discovery.txt"	"Voom_weights_discovery.txt"	"Voom_weights_discovery.txt"	"Voom_weights_discovery.txt"	""	"Voom_weights_discovery.txt"	""	""	"Voom_weights_discovery.txt"	"Voom_weights_discovery.txt"	""	""	"Voom_weights_discovery.txt"	"Voom_weights_discovery.txt"	"Voom_weights_discovery.txt"	"Voom_weights_discovery.txt"	"Voom_weights_discovery.txt"	"Voom_weights_discovery.txt"	""	"Voom_weights_discovery.txt"	"Voom_weights_discovery.txt"	"Voom_weights_discovery.txt"	"Voom_weights_discovery.txt"	""	"Voom_weights_discovery.txt"	""	"Voom_weights_discovery.txt"	""	""	"Voom_weights_discovery.txt"	""	""	"Voom_weights_discovery.txt"	"Voom_weights_discovery.txt"	"Voom_weights_discovery.txt"	""	""	""	"Voom_weights_discovery.txt"	"Voom_weights_discovery.txt"	""	"Voom_weights_discovery.txt"	"Voom_weights_discovery.txt"	"Voom_weights_discovery.txt"	""	"Voom_weights_discovery.txt"	"Voom_weights_discovery.txt"	"Voom_weights_discovery.txt"	""	""	"Voom_weights_discovery.txt"	"Voom_weights_discovery.txt"	"Voom_weights_discovery.txt"	"Voom_weights_discovery.txt"	""	"Voom_weights_discovery.txt"	""	"Voom_weights_discovery.txt"	"Voom_weights_discovery.txt"	""	"Voom_weights_discovery.txt"	""	"Voom_weights_discovery.txt"	""	""	"Voom_weights_discovery.txt"	"Voom_weights_discovery.txt"	""	"Voom_weights_discovery.txt"	"Voom_weights_discovery.txt"	""	"Voom_weights_discovery.txt"	""	""	""	""	"Voom_weights_discovery.txt"	"Voom_weights_discovery.txt"	"Voom_weights_discovery.txt"	""	""	""	"Voom_weights_discovery.txt"	"Voom_weights_discovery.txt"	"Voom_weights_discovery.txt"	"Voom_weights_discovery.txt"	"Voom_weights_discovery.txt"	"Voom_weights_discovery.txt"	""	"Voom_weights_discovery.txt"	""	""	"Voom_weights_discovery.txt"	"Voom_weights_discovery.txt"	"Voom_weights_discovery.txt"	""	"Voom_weights_discovery.txt"	"Voom_weights_discovery.txt"	""	"Voom_weights_discovery.txt"	"Voom_weights_discovery.txt"	"Voom_weights_discovery.txt"	""	"Voom_weights_discovery.txt"	""	""	""	"Voom_weights_discovery.txt"	"Voom_weights_discovery.txt"	"Voom_weights_discovery.txt"	""	"Voom_weights_discovery.txt"	""	""	"Voom_weights_discovery.txt"	""	"Voom_weights_discovery.txt"	"Voom_weights_discovery.txt"	""	"Voom_weights_discovery.txt"	""	""	"Voom_weights_discovery.txt"	"Voom_weights_discovery.txt"	"Voom_weights_discovery.txt"	""	""	""	"Voom_weights_discovery.txt"	"Voom_weights_discovery.txt"	"Voom_weights_discovery.txt"	"Voom_weights_discovery.txt"	"Voom_weights_discovery.txt"	""	"Voom_weights_discovery.txt"	"Voom_weights_discovery.txt"	"Voom_weights_discovery.txt"	"Voom_weights_discovery.txt"	"Voom_weights_discovery.txt"	"Voom_weights_discovery.txt"	"Voom_weights_discovery.txt"	"Voom_weights_discovery.txt"	""	""	""	""	"Voom_weights_discovery.txt"	""	"Voom_weights_discovery.txt"	""	""	"Voom_weights_discovery.txt"	"Voom_weights_discovery.txt"	"Voom_weights_discovery.txt"	""	"Voom_weights_discovery.txt"	"Voom_weights_discovery.txt"	"Voom_weights_discovery.txt"	"Voom_weights_discovery.txt"	"Voom_weights_discovery.txt"	""	""	""	"Voom_weights_discovery.txt"	"Voom_weights_discovery.txt"	"Voom_weights_discovery.txt"	"Voom_weights_discovery.txt"	""	"Voom_weights_discovery.txt"	"Voom_weights_discovery.txt"	"Voom_weights_discovery.txt"	""	"Voom_weights_discovery.txt"	""	"Voom_weights_discovery.txt"	"Voom_weights_discovery.txt"	""	"Voom_weights_discovery.txt"	""	"Voom_weights_discovery.txt"	""	"Voom_weights_discovery.txt"	"Voom_weights_discovery.txt"	"Voom_weights_discovery.txt"	"Voom_weights_discovery.txt"	""	""	"Voom_weights_discovery.txt"	"Voom_weights_discovery.txt"	"Voom_weights_discovery.txt"	""	"Voom_weights_discovery.txt"	""
!Sample_data_processing	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"	"base calling"
!Sample_data_processing	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"	"sequence mapping: sequences were mapped and gene expression quantified using using STAR with parameters: quantMode: GeneCounts; outSAMtype: None; outSAMmode: None; readFilesCommand: zcat and  ENSEMBL gene reference Homo sapiens GRCh38 DNA, release 96, downloaded from: ftp://ftp.ensembl.org/pub/release-96/fasta/homo_sapiens/dna/ . All other parameters were left at their default values for STAR version 2.7.1a"
!Sample_data_processing	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"	"counts QC: keep genes with expression counts per million > 2 in > 73 samples"
!Sample_data_processing	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"	"counts normalization (all samples dataset): Trimmed mean of M-values (TMM) normalization; software R, package edgeR"
!Sample_data_processing	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"	"differential expression normalization (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample == ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  design <- model.matrix(~0+phenotype+gender, data = dge$samples)  v <- voom(dge,design,plot=TRUE)  vfit <- lmFit(v,design)  contr.matrix <- makeContrasts(    Candidemia_Bacterial = Candidemia-Bacterial,    Candidemia_Healthy = Candidemia-Healthy,    Candidemia_SIRS = Candidemia-SIRS,    Candidemia_Viral = Candidemia-Viral,    Candidemia_others = Candidemia-1/4*Bacterial-1/4*Healthy-1/4*SIRS-1/4*Viral,    Bacterial_others = Bacterial-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Viral,    SIRS_others = SIRS-1/4*Candidemia-1/4*Healthy-1/4*Bacterial-1/4*Viral,    Viral_others = Viral-1/4*Candidemia-1/4*Healthy-1/4*SIRS-1/4*Bacterial,    levels = colnames(design)  )    vfit <- contrasts.fit(vfit, contrasts = contr.matrix)  efit <- eBayes(vfit)"
!Sample_data_processing	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"	"multivariate modeling normalization / processing (discovery samples only): Trimmed mean of M-values (TMM) noramlization, with voom normalization. Sample R code:     require(limma)  require(edgeR)  # Normalization steps  dge <- DGEList(counts=QCed_counts_discovery, samples = sample_characteristics[which(sample_characteristics$discovery_analysis_sample== ""Yes""),])  dge <- calcNormFactors(dge, method = ""TMM"")  data = t(cpm(dge, log = TRUE))  # use data as input to glmnet::cv.glmnet functions"
!Sample_data_processing	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"	"Genome_build: Homo sapiens GRCh38 DNA, release 96"
!Sample_data_processing	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for all samples and genes passing QC"
!Sample_data_processing	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"	"Supplementary_files_format_and_content: tab-delimited plain text file with gene counts for samples used for differential expression and model developemnt and genes passing QC"
!Sample_data_processing	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with the numeric matrix of normalized expression values on the log2 scale. Obtained from the ""$E"" argument of the limma::voom object. To be used with file ""voom_weights.txt"" when testing in limma::lmFit"
!Sample_data_processing	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"	"Supplementary_files_format_and_content: tab-delimited text file with numeric matrix of inverse variance weights from voom. Obtained from the ""$weights"" argument of the limma::voom object. To be used with file ""Voom_normalized_expression.txt"" when using limma::lmFit"
!Sample_platform_id	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"	"GPL24676"
!Sample_contact_name	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"	"Julie,,Steinbrink"
!Sample_contact_email	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"	"Julie.steinbrink@duke.edu"
!Sample_contact_department	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"	"Center for Applied Genomics and Precision Medicine"
!Sample_contact_institute	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"	"Duke University"
!Sample_contact_address	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"	"315 Trent Drive"
!Sample_contact_city	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"	"Durham"
!Sample_contact_state	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"	"NC"
!Sample_contact_zip/postal_code	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"	"27710"
!Sample_contact_country	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"	"USA"
!Sample_data_row_count	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"	"0"
!Sample_instrument_model	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"	"Illumina NovaSeq 6000"
!Sample_library_selection	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"	"cDNA"
!Sample_library_source	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"	"transcriptomic"
!Sample_library_strategy	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"	"RNA-Seq"
!Sample_relation	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591701"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591700"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591724"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591723"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591722"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591721"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591720"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591693"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591692"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591691"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591690"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591689"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591688"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591687"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591710"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591709"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591708"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591707"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19592282"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19592312"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19592311"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19592310"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19592309"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19592308"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19592307"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19592306"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19592305"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591841"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591840"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591839"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591838"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591837"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591836"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591871"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591870"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591869"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591868"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591867"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591866"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591865"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591863"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591862"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591861"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591860"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591859"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591858"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591879"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591878"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591877"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591857"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591856"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591884"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591883"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591882"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591881"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591880"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591876"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591719"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591718"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591717"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591716"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591715"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591714"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591713"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591712"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591711"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591835"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591741"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591739"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591737"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591735"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591733"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591732"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591730"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591729"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591728"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591727"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591726"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591725"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591855"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591854"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591847"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591846"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591845"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591844"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591843"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591842"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19592330"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19592329"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19592328"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19592327"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19592359"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19592358"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19592357"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19592356"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19592355"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19592354"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19592353"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19592352"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19592351"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19592350"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19592349"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19592348"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19592347"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19592346"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19592345"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19592344"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19592343"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591938"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19592342"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19592341"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19592366"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19592365"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19592364"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19592363"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19592362"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19592361"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19592360"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591937"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591936"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591935"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591934"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591933"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591932"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591931"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591930"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591929"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591928"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591927"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591955"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591954"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591953"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591952"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591951"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591950"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591949"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591948"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591947"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591946"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591944"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591943"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591942"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591941"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591969"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591945"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591968"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591967"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19592271"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19592270"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19592269"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19592296"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19592295"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19592294"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19592293"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19592292"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19592290"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19592289"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19592288"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19592287"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19592286"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19592285"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19592284"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19592283"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591662"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591661"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591673"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591671"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591669"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591667"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591666"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591665"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591664"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591663"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591660"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591686"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591685"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591684"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591683"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591682"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591681"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591680"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591679"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591678"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591677"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591676"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591675"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591674"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591699"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591695"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591694"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19592302"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19592301"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19592300"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19592299"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19592298"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591698"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591697"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19591696"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19592297"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19592326"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19592325"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19592324"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19592323"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19592322"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19592321"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19592320"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19592319"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19592318"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19592317"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19592316"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19592315"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19592314"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19592313"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19592340"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19592339"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19592338"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19592337"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19592336"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19592335"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19592334"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19592333"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19592332"	"BioSample: https://www.ncbi.nlm.nih.gov/biosample/SAMN19592331"
!Sample_relation	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081359"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081360"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081361"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081362"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081363"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081364"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081365"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081366"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081367"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081368"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081369"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081370"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081371"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081372"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081373"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081374"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081375"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081376"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081377"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081378"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081379"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081380"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081381"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081382"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081383"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081384"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081385"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081482"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081483"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081484"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081485"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081486"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081487"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081488"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081489"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081490"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081491"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081492"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081493"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081494"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081495"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081496"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081497"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081498"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081499"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081500"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081501"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081502"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081503"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081504"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081505"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081386"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081387"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081388"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081389"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081390"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081391"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081392"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081393"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081394"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081395"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081396"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081397"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081398"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081399"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081400"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081401"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081402"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081403"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081404"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081405"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081406"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081407"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081408"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081409"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081506"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081507"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081508"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081509"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081510"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081511"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081512"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081513"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081514"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081515"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081516"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081517"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081518"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081519"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081520"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081521"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081522"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081523"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081524"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081525"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081526"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081527"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081528"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081529"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081410"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081411"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081412"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081413"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081414"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081415"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081416"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081417"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081418"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081419"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081420"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081421"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081422"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081423"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081424"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081425"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081426"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081427"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081428"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081429"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081430"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081431"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081432"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081433"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081530"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081531"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081532"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081533"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081534"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081535"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081536"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081537"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081538"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081539"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081540"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081541"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081542"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081543"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081544"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081545"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081546"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081547"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081548"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081549"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081550"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081551"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081552"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081553"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081434"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081435"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081436"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081437"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081438"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081439"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081440"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081441"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081442"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081443"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081444"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081445"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081446"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081447"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081448"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081449"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081450"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081451"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081452"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081453"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081454"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081455"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081456"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081457"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081554"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081555"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081556"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081557"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081558"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081559"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081560"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081561"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081562"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081563"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081564"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081565"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081566"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081567"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081568"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081569"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081570"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081571"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081572"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081573"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081574"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081575"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081576"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081577"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081458"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081459"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081460"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081461"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081462"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081463"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081464"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081465"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081466"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081467"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081468"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081469"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081470"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081471"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081472"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081473"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081474"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081475"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081476"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081477"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081478"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081479"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081480"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081481"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081578"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081579"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081580"	"SRA: https://www.ncbi.nlm.nih.gov/sra?term=SRX11081581"
!Sample_supplementary_file_1	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"	"NONE"
!series_matrix_table_begin
"ID_REF"	"GSM5360763"	"GSM5360764"	"GSM5360765"	"GSM5360766"	"GSM5360767"	"GSM5360768"	"GSM5360769"	"GSM5360770"	"GSM5360771"	"GSM5360772"	"GSM5360773"	"GSM5360774"	"GSM5360775"	"GSM5360776"	"GSM5360777"	"GSM5360778"	"GSM5360779"	"GSM5360780"	"GSM5360781"	"GSM5360782"	"GSM5360783"	"GSM5360784"	"GSM5360785"	"GSM5360786"	"GSM5360787"	"GSM5360788"	"GSM5360789"	"GSM5360790"	"GSM5360791"	"GSM5360792"	"GSM5360793"	"GSM5360794"	"GSM5360795"	"GSM5360796"	"GSM5360797"	"GSM5360798"	"GSM5360799"	"GSM5360800"	"GSM5360801"	"GSM5360802"	"GSM5360803"	"GSM5360804"	"GSM5360805"	"GSM5360806"	"GSM5360807"	"GSM5360808"	"GSM5360809"	"GSM5360810"	"GSM5360811"	"GSM5360812"	"GSM5360813"	"GSM5360814"	"GSM5360815"	"GSM5360816"	"GSM5360817"	"GSM5360818"	"GSM5360819"	"GSM5360820"	"GSM5360821"	"GSM5360822"	"GSM5360823"	"GSM5360824"	"GSM5360825"	"GSM5360826"	"GSM5360827"	"GSM5360828"	"GSM5360829"	"GSM5360830"	"GSM5360831"	"GSM5360832"	"GSM5360833"	"GSM5360834"	"GSM5360835"	"GSM5360836"	"GSM5360837"	"GSM5360838"	"GSM5360839"	"GSM5360840"	"GSM5360841"	"GSM5360842"	"GSM5360843"	"GSM5360844"	"GSM5360845"	"GSM5360846"	"GSM5360847"	"GSM5360848"	"GSM5360849"	"GSM5360850"	"GSM5360851"	"GSM5360852"	"GSM5360853"	"GSM5360854"	"GSM5360855"	"GSM5360856"	"GSM5360857"	"GSM5360858"	"GSM5360859"	"GSM5360860"	"GSM5360861"	"GSM5360862"	"GSM5360863"	"GSM5360864"	"GSM5360865"	"GSM5360866"	"GSM5360867"	"GSM5360868"	"GSM5360869"	"GSM5360870"	"GSM5360871"	"GSM5360872"	"GSM5360873"	"GSM5360874"	"GSM5360875"	"GSM5360876"	"GSM5360877"	"GSM5360878"	"GSM5360879"	"GSM5360880"	"GSM5360881"	"GSM5360882"	"GSM5360883"	"GSM5360884"	"GSM5360885"	"GSM5360886"	"GSM5360887"	"GSM5360888"	"GSM5360889"	"GSM5360890"	"GSM5360891"	"GSM5360892"	"GSM5360893"	"GSM5360894"	"GSM5360895"	"GSM5360896"	"GSM5360897"	"GSM5360898"	"GSM5360899"	"GSM5360900"	"GSM5360901"	"GSM5360902"	"GSM5360903"	"GSM5360904"	"GSM5360905"	"GSM5360906"	"GSM5360907"	"GSM5360908"	"GSM5360909"	"GSM5360910"	"GSM5360911"	"GSM5360912"	"GSM5360913"	"GSM5360914"	"GSM5360915"	"GSM5360916"	"GSM5360917"	"GSM5360918"	"GSM5360919"	"GSM5360920"	"GSM5360921"	"GSM5360922"	"GSM5360923"	"GSM5360924"	"GSM5360925"	"GSM5360926"	"GSM5360927"	"GSM5360928"	"GSM5360929"	"GSM5360930"	"GSM5360931"	"GSM5360932"	"GSM5360933"	"GSM5360934"	"GSM5360935"	"GSM5360936"	"GSM5360937"	"GSM5360938"	"GSM5360939"	"GSM5360940"	"GSM5360941"	"GSM5360942"	"GSM5360943"	"GSM5360944"	"GSM5360945"	"GSM5360946"	"GSM5360947"	"GSM5360948"	"GSM5360949"	"GSM5360950"	"GSM5360951"	"GSM5360952"	"GSM5360953"	"GSM5360954"	"GSM5360955"	"GSM5360956"	"GSM5360957"	"GSM5360958"	"GSM5360959"	"GSM5360960"	"GSM5360961"	"GSM5360962"	"GSM5360963"	"GSM5360964"	"GSM5360965"	"GSM5360966"	"GSM5360967"	"GSM5360968"	"GSM5360969"	"GSM5360970"	"GSM5360971"	"GSM5360972"	"GSM5360973"	"GSM5360974"	"GSM5360975"	"GSM5360976"	"GSM5360977"	"GSM5360978"	"GSM5360979"	"GSM5360980"	"GSM5360981"	"GSM5360982"	"GSM5360983"	"GSM5360984"	"GSM5360985"
!series_matrix_table_end
